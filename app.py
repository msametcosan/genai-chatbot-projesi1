# --- 1. AdÄ±m: Gerekli ModÃ¼lleri Import Etme ---

# Ã–nbellek (Cache) hatasÄ±nÄ± Ã§Ã¶zmek iÃ§in bu bÃ¶lÃ¼m en Ã¼ste eklendi
# Hugging Face Spaces'in '/app' klasÃ¶rÃ¼ne yazma izni olmadÄ±ÄŸÄ±ndan,
# modelleri her zaman yazÄ±labilir olan '/tmp' klasÃ¶rÃ¼ne indirmesi iÃ§in ayar yapÄ±lÄ±yor.
import os
cache_dir = "/tmp/sentence_transformers_cache/"
os.makedirs(cache_dir, exist_ok=True)
os.environ["SENTENCE_TRANSFORMERS_HOME"] = cache_dir

import streamlit as st
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pandas as pd
import wikipedia
import time

# --- 2. AdÄ±m: Sayfa YapÄ±landÄ±rmasÄ± ve BaÅŸlÄ±k ---
# Streamlit sayfasÄ±nÄ±n temel ayarlarÄ± (baÅŸlÄ±k, ikon vb.) yapÄ±lÄ±r.
st.set_page_config(
    page_title="Akbank GenAI Bootcamp RAG Chatbot",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– Dinamik Bilgi KaynaklÄ± RAG Chatbot")
st.caption(
    f"Akbank GenAI Bootcamp Projesi - Wikipedia'dan alÄ±nan verilerle Gemini Pro ve FAISS kullanÄ±larak oluÅŸturulmuÅŸtur."
)

# --- 3. AdÄ±m: API AnahtarÄ± YapÄ±landÄ±rmasÄ± (Secrets'tan Okuma) ---
# Hugging Face Spaces'in "Secrets" bÃ¶lÃ¼mÃ¼nden API anahtarÄ±nÄ± gÃ¼venli bir ÅŸekilde okur.
try:
    GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
    if not GOOGLE_API_KEY:
        # Lokal veya Streamlit Cloud iÃ§in alternatif okuma yÃ¶ntemi
        GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY")
    if not GOOGLE_API_KEY:
        st.error(
            "âŒ GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen Hugging Face Spaces 'Secrets' bÃ¶lÃ¼mÃ¼ne ekleyin.")
        st.stop()
    genai.configure(api_key=GOOGLE_API_KEY)
except Exception as e:
    st.error(f"âŒ API anahtarÄ± yapÄ±landÄ±rÄ±lÄ±rken bir hata oluÅŸtu: {e}")
    st.stop()

# --- 4. AdÄ±m: Modelleri YÃ¼kleme (Cache ve HÄ±z Optimizasyonu ile) ---
# @st.cache_resource, modellerin her sayfa yenilemesinde deÄŸil, sadece bir kez yÃ¼klenmesini saÄŸlar.
# Bu, uygulamanÄ±n performansÄ±nÄ± ciddi ÅŸekilde artÄ±rÄ±r.
@st.cache_resource
def load_models():
    """Embedding ve Generative modelleri bir kez yÃ¼kler."""
    
    # Cache dizinini, fonksiyonun iÃ§inde de aÃ§Ä±kÃ§a tanÄ±mla
    cache_dir = "/tmp/sentence_transformers_cache/"
        
    with st.spinner("ğŸ§  Yapay zeka modelleri yÃ¼kleniyor... (Bu iÅŸlem yalnÄ±zca ilk aÃ§Ä±lÄ±ÅŸta biraz zaman alabilir)"):
        try:
            # Embedding modeli, 'cache_folder' parametresi ile doÄŸru yere indirilir.
            embedding_model = SentenceTransformer(
                'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                cache_folder=cache_dir 
            )
            
            # Yetkimiz olan ve stabil Ã§alÄ±ÅŸan 'gemini-pro-latest' modeli kullanÄ±lÄ±r.
            gen_model = genai.GenerativeModel('gemini-pro-latest')
            
            return embedding_model, gen_model
        
        except Exception as e:
            st.error(
                f"âŒ Modeller yÃ¼klenirken bir hata oluÅŸtu: {e}. LÃ¼tfen internet baÄŸlantÄ±nÄ±zÄ± kontrol edin veya sayfayÄ± yenileyin.")
            st.stop()

# Modelleri yÃ¼kle
embedding_model, gen_model = load_models()


# --- 5. AdÄ±m: Bilgi KaynaÄŸÄ± OluÅŸturma Fonksiyonu ---
# @st.cache_data, aynÄ± 'konu' ile Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda fonksiyonu tekrar Ã§alÄ±ÅŸtÄ±rmaz, cache'ten getirir.
# Bu, aynÄ± konu iÃ§in tekrar tekrar Wikipedia'dan veri Ã§ekmeyi ve embedding oluÅŸturmayÄ± engeller.
@st.cache_data(show_spinner=False)
def bilgi_kaynagi_olustur(konu):
    """
    Belirtilen konu hakkÄ±nda Wikipedia'dan bilgi alÄ±r, iÅŸler ve
    arama yapÄ±labilecek bir FAISS indeksi ile veri setini (DataFrame) dÃ¶ndÃ¼rÃ¼r.
    """
    try:
        with st.status(f"ğŸ“š '{konu}' hakkÄ±nda bilgi kaynaÄŸÄ± oluÅŸturuluyor...", expanded=True) as status:
            # AdÄ±m 5.1: Wikipedia'dan veriyi Ã§ek
            status.write(f"Wikipedia'dan '{konu}' konusu aranÄ±yor...")
            wikipedia.set_lang("tr")
            arama_sonuclari = wikipedia.search(konu)
            if not arama_sonuclari:
                st.error(f"âŒ '{konu}' ile ilgili bir Wikipedia sayfasÄ± bulunamadÄ±.")
                status.update(label="âŒ Konu bulunamadÄ±.", state="error")
                return None, None, None

            sayfa_basligi = arama_sonuclari[0]
            page = wikipedia.page(sayfa_basligi, auto_suggest=False)
            status.write(f"ğŸ“„ '{page.title}' sayfasÄ± baÅŸarÄ±yla bulundu ve iÅŸleniyor.")
            
            # AdÄ±m 5.2: Metni parÃ§alara (Chunks) ayÄ±r
            chunks = []
            paragraflar = page.content.split('\n\n')
            for p in paragraflar:
                if len(p.strip()) > 100: # AnlamsÄ±z derecede kÄ±sa paragraflarÄ± atla
                    chunks.append({'source': page.title, 'text': p.strip()})
            
            if not chunks:
                st.error("âŒ Sayfa iÃ§eriÄŸi iÅŸlenecek kadar uzun paragraflara ayrÄ±lamadÄ±.")
                status.update(label="âŒ Sayfa iÃ§eriÄŸi yetersiz.", state="error")
                return None, None, None

            df_chunks = pd.DataFrame(chunks)
            status.write(f"ğŸ§© {len(df_chunks)} adet metin parÃ§asÄ± (chunk) vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
            
            # AdÄ±m 5.3: ParÃ§alarÄ± vektÃ¶rlere (Embeddings) dÃ¶nÃ¼ÅŸtÃ¼r
            embeddings = embedding_model.encode(df_chunks['text'].tolist(), show_progress_bar=False)
            df_chunks['embeddings'] = list(embeddings)
            
            # AdÄ±m 5.4: VektÃ¶r veritabanÄ±nÄ± (FAISS Index) oluÅŸtur
            embeddings_array = np.array(df_chunks['embeddings'].tolist()).astype('float32')
            d = embeddings_array.shape[1]
            index = faiss.IndexFlatL2(d)
            index.add(embeddings_array)
            
            status.write("âœ… FAISS arama indeksi baÅŸarÄ±yla oluÅŸturuldu.")
            time.sleep(1)
            status.update(label=f"âœ… '{page.title}' konusu sohbete hazÄ±r!", state="complete")
            
            return df_chunks, index, page.title

    # Hata yÃ¶netimi
    except wikipedia.exceptions.PageError:
        st.error(f"âŒ '{konu}' adÄ±nda bir Wikipedia sayfasÄ± bulunamadÄ±.")
        return None, None, None
    except wikipedia.exceptions.DisambiguationError as e:
        st.error(f"âŒ '{konu}' birden Ã§ok anlama geliyor. LÃ¼tfen daha spesifik olun. (Ã–rn: {e.options[:3]})")
        return None, None, None
    except Exception as e:
        st.error(f"âŒ Bilgi kaynaÄŸÄ± oluÅŸturulurken beklenmedik bir hata oluÅŸtu: {e}")
        return None, None, None


# --- 6. AdÄ±m: Soru Cevaplama Fonksiyonu (RAG Pipeline) ---
def soru_cevapla(soru, df_chunks, index):
    """
    KullanÄ±cÄ± sorusunu ve oluÅŸturulan bilgi kaynaÄŸÄ±nÄ± (index) kullanarak cevap Ã¼retir.
    """
    try:
        # AdÄ±m 6.1: KullanÄ±cÄ±nÄ±n sorusunu vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼r
        soru_vector = embedding_model.encode([soru]).astype('float32')

        # AdÄ±m 6.2: FAISS'te en alakalÄ± metin parÃ§alarÄ±nÄ± bul (Retrieval)
        k = 5 # En alakalÄ± 5 metin parÃ§asÄ±nÄ± getir
        distances, indices = index.search(soru_vector, k)
        relevant_chunks = [df_chunks.iloc[i]['text'] for i in indices[0]]
        context = "\n\n".join(relevant_chunks)
        
        # AdÄ±m 6.3: Modeli bilgilendirerek cevap Ã¼ret (Augmented Generation)
        prompt = f"""AÅŸaÄŸÄ±daki BÄ°LGÄ°LER bÃ¶lÃ¼mÃ¼nde verilen metinleri kullanarak SORU'yu cevapla.
CevabÄ±nÄ± yalnÄ±zca ve yalnÄ±zca sana verilen bu BÄ°LGÄ°LER'e dayandÄ±r. EÄŸer bilgiler soruyu cevaplamak iÃ§in yetersizse, 'Bu konuda bilgim yok.' de.

BÄ°LGÄ°LER:
{context}

SORU: {soru}

CEVAP:"""

        response = gen_model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"âŒ Cevap Ã¼retilirken bir hata oluÅŸtu: {e}")
        return "ÃœzgÃ¼nÃ¼m, cevap Ã¼retirken teknik bir sorunla karÅŸÄ±laÅŸtÄ±m."


# --- 7. AdÄ±m: Ana Uygulama ArayÃ¼zÃ¼ ve Sohbet MantÄ±ÄŸÄ± ---

# Session state (oturum hafÄ±zasÄ±) baÅŸlatma
# Bu, sayfa yenilense bile deÄŸiÅŸkenlerin (konu, chat geÃ§miÅŸi) kaybolmamasÄ±nÄ± saÄŸlar.
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_topic" not in st.session_state:
    st.session_state.current_topic = ""
if "current_index" not in st.session_state:
    st.session_state.current_index = None
if "current_df" not in st.session_state:
    st.session_state.current_df = None

# --- Yan MenÃ¼ (Sidebar) ---
with st.sidebar:
    st.header("Konu SeÃ§imi")
    st.markdown("""
    Chatbot'un hangi Wikipedia konusu hakkÄ±nda konuÅŸacaÄŸÄ±nÄ± buradan belirleyebilirsiniz.
    """)
    
    yeni_konu = st.text_input("Wikipedia Konusu Girin:", placeholder="Ã–rn: Yapay zeka")
    
    if st.button("Yeni Konuyu Ayarla", type="primary"):
        if yeni_konu:
            # Yeni bir konu ayarlandÄ±ÄŸÄ±nda, hafÄ±zayÄ± ve sohbet geÃ§miÅŸini temizle
            st.session_state.current_topic = yeni_konu
            st.session_state.messages = []
            
            # Bilgi kaynaÄŸÄ±nÄ± oluÅŸtur ve session state'e kaydet
            df, index, title = bilgi_kaynagi_olustur(yeni_konu)
            
            if df is not None and index is not None:
                st.session_state.current_df = df
                st.session_state.current_index = index
                st.session_state.current_topic = title
            else:
                # BaÅŸarÄ±sÄ±z olduysa konuyu sÄ±fÄ±rla
                st.session_state.current_topic = ""
                st.session_state.current_df = None
                st.session_state.current_index = None
        else:
            st.sidebar.warning("LÃ¼tfen bir konu adÄ± girin.")
            
    st.divider()
    # Ã–NEMLÄ°: Buradaki linki kendi GitHub reponuzun linkiyle deÄŸiÅŸtirmeyi unutmayÄ±n!
    st.markdown("Proje dÃ¶kÃ¼manÄ±na [buradan](https://github.com/muratdrd/akbank-genai-chatbot) ulaÅŸabilirsiniz.") 

# --- Ana Sohbet AlanÄ± ---
# Konu seÃ§ilmemiÅŸse, kullanÄ±cÄ±yÄ± bilgilendir
if not st.session_state.current_topic:
    st.info("LÃ¼tfen sohbete baÅŸlamak iÃ§in kenar Ã§ubuÄŸundan bir Wikipedia konusu belirleyin.")
    st.stop()

# Konu seÃ§ildiyse, sohbet arayÃ¼zÃ¼nÃ¼ gÃ¶ster
st.info(f"Åu anki sohbet konusu: **{st.session_state.current_topic}** (Wikipedia'dan alÄ±ndÄ±)")

# GeÃ§miÅŸ mesajlarÄ± ekrana yazdÄ±r
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# KullanÄ±cÄ±dan yeni soru giriÅŸi (chat_input)
if prompt := st.chat_input(f"'{st.session_state.current_topic}' hakkÄ±nda bir soru sorun..."):
    
    # KullanÄ±cÄ±nÄ±n sorusunu ekle ve gÃ¶ster
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Chatbot'un cevabÄ±nÄ± Ã¼ret ve gÃ¶ster
    with st.chat_message("assistant"):
        with st.spinner("Cevap oluÅŸturuluyor..."):
            cevap = soru_cevapla(prompt, st.session_state.current_df, st.session_state.current_index)
            st.markdown(cevap)
    
    # Chatbot'un cevabÄ±nÄ± hafÄ±zaya ekle
    st.session_state.messages.append({"role": "assistant", "content": cevap})
